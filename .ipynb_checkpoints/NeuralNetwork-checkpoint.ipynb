{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e9afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff43012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "all_dfs = []\n",
    "directory = os.fsencode(\"face data/\")\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith(\"0.csv\"): \n",
    "        df = pd.read_csv(\"face data/\" + filename, header=None)\n",
    "        if (filename.endswith(\"10.csv\")):\n",
    "            df.loc[df[0] == 10, 0] = 1\n",
    "        all_dfs.append(df)\n",
    "len(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cdc537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.189055</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.185022</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302013</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.153488</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.113990</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218310</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.251534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174129</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.150376</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7    \\\n",
       "0   0.0  0.188679  0.152284  0.013953  0.011299  0.716981  0.903704  0.940397   \n",
       "1   0.0  0.321429  0.115385  0.000000  0.210843  0.465969  0.894309  0.914062   \n",
       "2   0.0  0.185022  0.143519  0.063063  0.000000  0.513333  0.767606  0.854167   \n",
       "3   0.0  0.472826  0.264151  0.065421  0.000000  0.598540  0.769737  0.912409   \n",
       "4   0.0  0.266234  0.153488  0.074074  0.000000  0.570470  0.796875  0.921429   \n",
       "..  ...       ...       ...       ...       ...       ...       ...       ...   \n",
       "15  1.0  0.200000  0.166667  0.090909  0.800000  0.000000  0.218310  0.356250   \n",
       "16  1.0  0.000000  0.076923  0.000000  0.767857  0.045455  0.073529  0.278481   \n",
       "17  1.0  0.100000  0.000000  0.000000  0.551724  0.044444  0.090909  0.190083   \n",
       "18  1.0  0.000000  0.100000  0.214286  0.855422  0.273684  0.053030  0.264516   \n",
       "19  1.0  0.000000  0.100000  0.181818  0.904762  0.121212  0.150376  0.414013   \n",
       "\n",
       "         8         9    ...       775       776       777       778       779  \\\n",
       "0   0.920290  0.949640  ...  0.042254  0.021429  0.242857  0.280899  0.211268   \n",
       "1   0.927007  0.909774  ...  0.048485  0.000000  0.300000  0.179724  0.153846   \n",
       "2   0.896296  0.862069  ...  0.302013  0.170068  0.235577  0.066667  0.000000   \n",
       "3   0.891667  0.850340  ...  0.006410  0.013605  0.202703  0.094340  0.142157   \n",
       "4   0.909774  0.868966  ...  0.000000  0.355263  0.068027  0.219512  0.113990   \n",
       "..       ...       ...  ...       ...       ...       ...       ...       ...   \n",
       "15  0.251534  0.000000  ...  0.741667  0.825175  0.778523  0.876543  1.000000   \n",
       "16  0.145161  0.096774  ...  0.854839  0.807143  0.842105  0.968037  1.000000   \n",
       "17  0.000000  0.000000  ...  0.850746  0.803279  0.875776  0.993377  0.000000   \n",
       "18  0.138889  0.233083  ...  0.779412  0.837838  0.840909  0.957831  0.986111   \n",
       "19  0.092199  0.000000  ...  0.814607  0.801471  0.708955  0.844720  1.000000   \n",
       "\n",
       "         780       781       782       783       784  \n",
       "0   0.189055  0.085714  0.000000  0.000000  0.000000  \n",
       "1   0.098901  0.000000  0.000000  0.000000  0.093750  \n",
       "2   0.086614  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.122807  0.123596  0.000000  0.729730  0.365854  \n",
       "4   0.052941  0.302521  0.000000  0.217391  0.325581  \n",
       "..       ...       ...       ...       ...       ...  \n",
       "15  0.890476  0.275000  0.201923  0.467836  0.016667  \n",
       "16  0.174129  0.096154  0.000000  0.000000  0.050847  \n",
       "17  0.229167  0.652381  0.594203  0.180328  0.108108  \n",
       "18  0.231818  0.004854  0.035000  0.000000  0.443820  \n",
       "19  0.077295  0.107143  0.217822  0.000000  0.419753  \n",
       "\n",
       "[469 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat(all_dfs)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e88912f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.949640</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.242857</td>\n",
       "      <td>0.280899</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.189055</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.927007</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.917241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.179724</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185022</td>\n",
       "      <td>0.143519</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.513333</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.896296</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.819444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302013</td>\n",
       "      <td>0.170068</td>\n",
       "      <td>0.235577</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472826</td>\n",
       "      <td>0.264151</td>\n",
       "      <td>0.065421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>0.769737</td>\n",
       "      <td>0.912409</td>\n",
       "      <td>0.891667</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>0.801370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.013605</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>0.142157</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.123596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.365854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.153488</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.909774</td>\n",
       "      <td>0.868966</td>\n",
       "      <td>0.856164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.068027</td>\n",
       "      <td>0.219512</td>\n",
       "      <td>0.113990</td>\n",
       "      <td>0.052941</td>\n",
       "      <td>0.302521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.325581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218310</td>\n",
       "      <td>0.356250</td>\n",
       "      <td>0.251534</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.825175</td>\n",
       "      <td>0.778523</td>\n",
       "      <td>0.876543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890476</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.201923</td>\n",
       "      <td>0.467836</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.278481</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174129</td>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.190083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.875776</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.594203</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.053030</td>\n",
       "      <td>0.264516</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.233083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.840909</td>\n",
       "      <td>0.957831</td>\n",
       "      <td>0.986111</td>\n",
       "      <td>0.231818</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.150376</td>\n",
       "      <td>0.414013</td>\n",
       "      <td>0.092199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.708955</td>\n",
       "      <td>0.844720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>469 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1         2         3         4         5         6         7    \\\n",
       "0   0.188679  0.152284  0.013953  0.011299  0.716981  0.903704  0.940397   \n",
       "1   0.321429  0.115385  0.000000  0.210843  0.465969  0.894309  0.914062   \n",
       "2   0.185022  0.143519  0.063063  0.000000  0.513333  0.767606  0.854167   \n",
       "3   0.472826  0.264151  0.065421  0.000000  0.598540  0.769737  0.912409   \n",
       "4   0.266234  0.153488  0.074074  0.000000  0.570470  0.796875  0.921429   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "15  0.200000  0.166667  0.090909  0.800000  0.000000  0.218310  0.356250   \n",
       "16  0.000000  0.076923  0.000000  0.767857  0.045455  0.073529  0.278481   \n",
       "17  0.100000  0.000000  0.000000  0.551724  0.044444  0.090909  0.190083   \n",
       "18  0.000000  0.100000  0.214286  0.855422  0.273684  0.053030  0.264516   \n",
       "19  0.000000  0.100000  0.181818  0.904762  0.121212  0.150376  0.414013   \n",
       "\n",
       "         8         9         10   ...       775       776       777       778  \\\n",
       "0   0.920290  0.949640  0.923077  ...  0.042254  0.021429  0.242857  0.280899   \n",
       "1   0.927007  0.909774  0.917241  ...  0.048485  0.000000  0.300000  0.179724   \n",
       "2   0.896296  0.862069  0.819444  ...  0.302013  0.170068  0.235577  0.066667   \n",
       "3   0.891667  0.850340  0.801370  ...  0.006410  0.013605  0.202703  0.094340   \n",
       "4   0.909774  0.868966  0.856164  ...  0.000000  0.355263  0.068027  0.219512   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "15  0.251534  0.000000  0.000000  ...  0.741667  0.825175  0.778523  0.876543   \n",
       "16  0.145161  0.096774  0.000000  ...  0.854839  0.807143  0.842105  0.968037   \n",
       "17  0.000000  0.000000  0.000000  ...  0.850746  0.803279  0.875776  0.993377   \n",
       "18  0.138889  0.233083  0.000000  ...  0.779412  0.837838  0.840909  0.957831   \n",
       "19  0.092199  0.000000  0.000000  ...  0.814607  0.801471  0.708955  0.844720   \n",
       "\n",
       "         779       780       781       782       783       784  \n",
       "0   0.211268  0.189055  0.085714  0.000000  0.000000  0.000000  \n",
       "1   0.153846  0.098901  0.000000  0.000000  0.000000  0.093750  \n",
       "2   0.000000  0.086614  0.000000  0.000000  0.000000  0.000000  \n",
       "3   0.142157  0.122807  0.123596  0.000000  0.729730  0.365854  \n",
       "4   0.113990  0.052941  0.302521  0.000000  0.217391  0.325581  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "15  1.000000  0.890476  0.275000  0.201923  0.467836  0.016667  \n",
       "16  1.000000  0.174129  0.096154  0.000000  0.000000  0.050847  \n",
       "17  0.000000  0.229167  0.652381  0.594203  0.180328  0.108108  \n",
       "18  0.986111  0.231818  0.004854  0.035000  0.000000  0.443820  \n",
       "19  1.000000  0.077295  0.107143  0.217822  0.000000  0.419753  \n",
       "\n",
       "[469 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, [i for i in range(1, 785)]]\n",
    "Y = data.iloc[:, 0]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3ae994",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Data = []\n",
    "for _, row in X.iterrows():\n",
    "    X_Data.append(np.array(row).reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cbaea2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(X_Data)):\n",
    "    plt.imshow(X_Data[i], cmap=\"gray\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b6947a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X_Data, Y, test_size = 0.30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d6748134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328, 28, 28, 1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Train = np.array(X_Train).reshape(len(X_Train), 28, 28, 1)\n",
    "X_Test = np.array(X_Test).reshape(len(X_Test), 28, 28, 1)\n",
    "Y_Train = np.array(Y_Train)\n",
    "Y_Tests = np.array(Y_Test)\n",
    "X_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dda27bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_75 (Conv2D)           (None, 27, 27, 20)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_74 (MaxPooling (None, 13, 13, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 11, 11, 50)        9050      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling (None, 5, 5, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 1250)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 500)               625500    \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 886,152\n",
      "Trainable params: 886,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(20, (2,2), strides=1, activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "  tf.keras.layers.Conv2D(50, (3,3), strides=1, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(500, activation='relu'),\n",
    "  tf.keras.layers.Dense(500, activation='relu'),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9ed6a8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 2s 23ms/step - loss: 0.7041 - accuracy: 0.3924\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6908 - accuracy: 0.5246\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.5374\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6860 - accuracy: 0.5143\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.6677 - accuracy: 0.5831\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.6793 - accuracy: 0.5224\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6773 - accuracy: 0.5044\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6606 - accuracy: 0.5725\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.6622 - accuracy: 0.5409\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6562 - accuracy: 0.7843 0s - loss: 0.6550 - accuracy: 0. - ETA: 0s - loss: 0.6564 - accuracy: 0.\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6447 - accuracy: 0.5800\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6334 - accuracy: 0.5975\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.6410 - accuracy: 0.7566\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.6311 - accuracy: 0.7918\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6172 - accuracy: 0.7436\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.6085 - accuracy: 0.7564\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.6024 - accuracy: 0.7583\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5950 - accuracy: 0.8359\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5812 - accuracy: 0.7823\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5693 - accuracy: 0.7313\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5474 - accuracy: 0.8080\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.5201 - accuracy: 0.7617\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4998 - accuracy: 0.8812\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.5053 - accuracy: 0.7953\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5174 - accuracy: 0.7780\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.5096 - accuracy: 0.7819\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.4789 - accuracy: 0.7760\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.4692 - accuracy: 0.8300\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.5388 - accuracy: 0.7519\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.3956 - accuracy: 0.8604\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.4186 - accuracy: 0.8139\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.3814 - accuracy: 0.8621\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 0.3628 - accuracy: 0.8432\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.3156 - accuracy: 0.9113\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.3586 - accuracy: 0.8423\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.3034 - accuracy: 0.8986\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.3394 - accuracy: 0.8509\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.2532 - accuracy: 0.9035\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2455 - accuracy: 0.9287\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2369 - accuracy: 0.9242\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.2004 - accuracy: 0.9400\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 0.3583 - accuracy: 0.8155\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.3073 - accuracy: 0.8605\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1888 - accuracy: 0.9398\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.2080 - accuracy: 0.9313\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 0.1918 - accuracy: 0.9325\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 0.1528 - accuracy: 0.9667\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1957 - accuracy: 0.9239\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 0.1794 - accuracy: 0.9236\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 0.1157 - accuracy: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1468470df10>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_Train, Y_Train, batch_size = 25, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cdce5354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 8ms/step - loss: 1.8301 - accuracy: 0.5177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8301454782485962, 0.5177304744720459]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_Test, Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "7e43706c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Pred = np.argmax(model.predict(X_Test), axis=-1)\n",
    "both = np.vstack((np.array(Y_Test), Y_Pred)).T.astype(np.int)\n",
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6b630180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54, 0.46],\n",
       "       [0.5 , 0.5 ]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con_mat = tf.math.confusion_matrix(labels=Y_Test, predictions=Y_Pred).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "con_mat_norm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
